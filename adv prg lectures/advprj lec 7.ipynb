{"cells":[{"cell_type":"markdown","metadata":{"id":"5Q5VupzuvJVE"},"source":["Convolutional Neural Networks (CNNs)\n","\n","A Convolutional Neural Network (CNN) is a deep learning model specifically designed for processing structured grid-like data, such as images.\n","\n","Structure of CNNs:\n","\n","1. Convolutional Layers\n","\n","2. Pooling Layers -- MaxPooling, AveragePooling -- dimensionality reduction or downsizing the size\n","\n","3. Fully Connected (Dense) Layers.\n","\n","\n","convolution + pooling = feature extractions\n","before dense layer there is flatling layer\n","\n","by default there is no padding , without it feature map will be shrink, to avoid that we use padding othre wise dimensions will be changed after pooling"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1770731110517,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"kicM7oS9yPrb"},"outputs":[],"source":["#CIFAR-10 - popular dataset for image classification with 10 classes\n","\n","from tensorflow import keras\n","\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,Dense,Dropout\n","\n","from tensorflow.keras.datasets import cifar10\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7990,"status":"ok","timestamp":1770731163384,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"GF5Kfp87yb1p","outputId":"4d134c02-d361-45ac-8307-05feae7a3793"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"]}],"source":["#load CIFAR dataset\n","(X_train,y_train),(X_test,y_test) = cifar10.load_data()\n","\n","#Normalize the pixel values\n","X_train,X_test = X_train / 255.0, X_test/255"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1770731385253,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"1y3g5-hmzS7B"},"outputs":[],"source":["#convert labels to one-hot encoding\n","y_train = keras.utils.to_categorical(y_train, num_classes = 10)\n","y_test = keras.utils.to_categorical(y_test, num_classes = 10)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1770731901690,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"EXNisDuK0LBI","outputId":"f6e4d82a-6d23-4ca8-deb2-f67c43d8b898"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["#build CNN MODEL\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),  #32 at start is no of features . and in input shape 3 represent no of channels (RGB)\n","    MaxPooling2D(2,2),  # downsampled to 2 by 2\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Conv2D(128, (3,3), activation='relu'),\n","    Flatten(),\n","    Dense(128, activation='relu'), # this is fully connected layer or dense layer before giving input here we have to flatten it from vector to 1d vector\n","    Dropout(0.6), #prevent overfitting  , its a regularization parameter, sooo 60% of neuran are deactivated\n","    Dense(10, activation='softmax')  # for classification task we have to provide activation function , for binary it will be sigmoid, 10 means 10 classes\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1770731962265,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"G4PDzYCM1RJA"},"outputs":[],"source":["#compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # why categorical_crossentropy becz its a classification taks and metrics to evalutate wil  be accuracy"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1770731963198,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"j1mLutm_2Nup","outputId":"f22f904f-7acf-436b-c5c5-3d89e0daeba3"},"outputs":[{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"sequential_1\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)                    \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape           \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e       Param # \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d_3 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv2D\u003c/span\u003e)               │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e30\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)     │           \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e896\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eMaxPooling2D\u003c/span\u003e)  │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)     │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_4 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv2D\u003c/span\u003e)               │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e13\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e13\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)     │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e18,496\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_3 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eMaxPooling2D\u003c/span\u003e)  │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)       │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_5 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv2D\u003c/span\u003e)               │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)      │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e73,856\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eFlatten\u003c/span\u003e)             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2048\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                 │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)            │       \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e262,272\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)            │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                 │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e10\u003c/span\u003e)             │         \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1,290\u003c/span\u003e │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e356,810\u003c/span\u003e (1.36 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m356,810\u001b[0m (1.36 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e356,810\u003c/span\u003e (1.36 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m356,810\u001b[0m (1.36 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e (0.00 B)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"1jPpXWd-2gna"},"source":["without padding 32 by 32 to 30 by 30 in conv2d\n","\n","\n","\n"," in total param and trainable parameter\n","we have to adjust bais and weights to all the layers\n","\n","\n","in transfer learning only some of the layers are trainable"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":762268,"status":"ok","timestamp":1770733051184,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"ytL9gPks3SCz","outputId":"81973b9a-68ed-4eb2-8ba1-a473cfd01469"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 89ms/step - accuracy: 0.2946 - loss: 1.8829 - val_accuracy: 0.5393 - val_loss: 1.2902\n","Epoch 2/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 91ms/step - accuracy: 0.5075 - loss: 1.3786 - val_accuracy: 0.5931 - val_loss: 1.1425\n","Epoch 3/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 85ms/step - accuracy: 0.5742 - loss: 1.2070 - val_accuracy: 0.6494 - val_loss: 1.0059\n","Epoch 4/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 87ms/step - accuracy: 0.6179 - loss: 1.0906 - val_accuracy: 0.6595 - val_loss: 0.9683\n","Epoch 5/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 86ms/step - accuracy: 0.6525 - loss: 1.0020 - val_accuracy: 0.6853 - val_loss: 0.9078\n","Epoch 6/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 83ms/step - accuracy: 0.6813 - loss: 0.9240 - val_accuracy: 0.6931 - val_loss: 0.8772\n","Epoch 7/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.7014 - loss: 0.8698 - val_accuracy: 0.7175 - val_loss: 0.8152\n","Epoch 8/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 86ms/step - accuracy: 0.7204 - loss: 0.8104 - val_accuracy: 0.7241 - val_loss: 0.7990\n","Epoch 9/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.7295 - loss: 0.7797 - val_accuracy: 0.7118 - val_loss: 0.8546\n","Epoch 10/10\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 85ms/step - accuracy: 0.7363 - loss: 0.7585 - val_accuracy: 0.7277 - val_loss: 0.7857\n"]}],"source":["#train the model\n","history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQksoVj53iBD"},"outputs":[],"source":["test_acc = model.evaluate(X_test, y_test)\n","print(f'Test Accuracy : {test_acc}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPebUlaK4Qlc"},"outputs":[],"source":["#MNIST dataset - contains gray scale 28x28 images of handwritten digits"]},{"cell_type":"markdown","metadata":{"id":"4oiJtwOY4Zcq"},"source":["IMPROVEMENTS\n","\n","check images  date 10feb 3:09 - 3:10\n"]},{"cell_type":"markdown","metadata":{"id":"Gc0xWriS5cQO"},"source":["                         ..                    "]},{"cell_type":"markdown","metadata":{"id":"w3QG8Ybe5cHX"},"source":["**Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM)**\n","\n","Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are types of neural networks specifically designed to process sequential data, such as time series, speech, or text.\n","\n","1. RNN\n","\n","- Sequential Data\n","- Memory Cells # it has ability to maintain info overtime\n","- Challenges with RNNs # longterm dependencies ( hist data of 1 or more years) there is a vanishing gradient problem, when we try to adjust weight the previous weights will be gone from the memory to avoid this we have LSTM\n","\n","\n","2. LSTM\n","\n","- Structure of an LSTM: Forget Gate, Input Gate, Output Gate\n","\n","- An LSTM has three gates (gating mechanism):\n","      Forget Gate: Decides which information from the previous time step should be discarded.\n","\n","      Input Gate: Determines which new information should be added to the memory.\n","\n","      Output Gate: Controls which part of the memory should be output to the next step.( Determines what the next hidden state should be)\n","-  Benefits of LSTM\n","    Text processing , speech data and time series both are goood choices"]},{"cell_type":"markdown","metadata":{"id":"DbCfAcxp6b5h"},"source":["Pre-processing Steps for Text Data\n","\n","1. Text Cleaning\n","2. Tokenization #splitting the text into small words knowns as tokens\n","3. Stopword Removal\n","4. Stemming # ing words like RUNNING\n","5. Lemmatization # good- better same\n","6. Removing Non-Alphabetic Characters\n","7. Handling Imbalanced Data\n","8. Text Vectorization # bag of words comes under this like how many times a particular text is present\n","9. Removing Rare Words\n","10. Handling Negations\n","\n","\n","#CHECK IMG 3:22\n","NLP TAKS  --- Preprocessing steps"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90,"status":"ok","timestamp":1770733509459,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"CYVrDJb46bZC","outputId":"56ceacc2-7b11-45df-a0f6-d4b83da5fe3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Download complete: tiny shakespeare.txt\n"]}],"source":["#RNN for next- word prediction using shakespereblabla dataset\n","import requests\n","\n","# URL of the dataset\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","\n","# Download the content\n","response = requests.get(url)\n","\n","# Save it to a file\n","with open(\"tiny_shakespeare.txt\", \"w\", encoding=\"utf-8\") as file:\n","    file.write(response.text)\n","\n","print(\"Download complete: tiny shakespeare.txt\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1770733790222,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"C_DU3tNn8GXS"},"outputs":[],"source":["#Import Libraries\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Dropout\n","import numpy as np\n","\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1770733930768,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"22dtB4Ps9EPc"},"outputs":[],"source":["#load the data\n","with open(\"tiny_shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n","    shakespeare_text = file.read().lower()"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1770734100865,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"XbAWTbHa9rT7"},"outputs":[],"source":["# create a sorted list\n","chars = sorted(set(shakespeare_text))\n","\n","#create a dictionary\n","char_to_index = {char : idx for idx, char in enumerate(chars)}\n","\n","#create a reverse dictionary\n","index_to_char = {idx : char for idx, char in enumerate(chars)}\n","\n","vocab_size = len(chars)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":278,"status":"ok","timestamp":1770734647663,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"2aa_usX7-W6b"},"outputs":[],"source":["#convert text to character indices\n","text_as_int = np.array([char_to_index[char] for char in shakespeare_text])\n","\n","#setting the sequence Length\n","sequence_length = 100\n","examples_per_epoch = len(shakespeare_text) // (sequence_length + 1)\n","\n","#create the input and target\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","sequences = char_dataset.batch(sequence_length + 1, drop_remainder=True)\n","\n","#split the sequences into X and y\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text = chunk[1:]\n","  return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)\n","\n","BATCH_SIZE = 64 # Define BATCH_SIZE here\n","BUFFER_SIZE = 10000\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1770734956945,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"f1VtHaK5AxQ8"},"outputs":[],"source":["#Build a simple RNN model\n","model_rnn = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=256),\n","    SimpleRNN(1024, return_sequences=True, stateful=False, recurrent_initializer='glorot_uniform'),\n","    Dense(vocab_size, activation='softmax') ])"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1770734988110,"user":{"displayName":"Vedant Patil","userId":"10047165121123758137"},"user_tz":-60},"id":"RGoysWXgA7P2"},"outputs":[],"source":["#compile the model\n","\n","model_rnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2cQrrHZEBUj6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 2s/step - accuracy: 0.2110 - loss: 2.8744\n","Epoch 2/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 2s/step - accuracy: 0.4024 - loss: 2.0138\n","Epoch 3/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 2s/step - accuracy: 0.4765 - loss: 1.7502\n","Epoch 4/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 2s/step - accuracy: 0.5154 - loss: 1.6051\n","Epoch 5/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 2s/step - accuracy: 0.5359 - loss: 1.5203\n","Epoch 6/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.5491 - loss: 1.4663\n","Epoch 7/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 2s/step - accuracy: 0.5591 - loss: 1.4293\n","Epoch 8/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 2s/step - accuracy: 0.5660 - loss: 1.3963\n","Epoch 9/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 2s/step - accuracy: 0.5715 - loss: 1.3723\n","Epoch 10/20\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 1.3446\n","Epoch 11/20\n","\u001b[1m 63/172\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:27\u001b[0m 2s/step - accuracy: 0.5828 - loss: 1.3276"]}],"source":["#Train the model\n","\n","EPOCHS = 20 #change this value based on performance\n","history = model_rnn.fit(dataset, epochs=EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-zUICIgBfKM"},"outputs":[],"source":["#Define the model (switch between RNN and LSTM)\n","\n","def build_model(vocab_size, embedding_dim, rnn_units, batch_size, use_lstm = True):\n","\n","model = Sequential([\n","    Embedding(vocab_size,embedding_dim, input_length=sequence_length),\n","    LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform')\n","    if use lstm else\n","    SimpleRNN(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n","    Dense(vocab_size)\n","\n","return_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiYrqh8QCVxf"},"outputs":[],"source":["#hyperparaneters\n","embedding_dim = 256\n","rnn_units = 1024\n","use_lstm = TRUE # change to false for simple RNN\n","sequence_length = 100\n","model_lstm = build_model(vocab_size,embedding_dim, rnn_units, sequence_length, use_lstm)"]},{"cell_type":"markdown","metadata":{"id":"ceatoUuADP4g"},"source":["#LSTM\n","IMPROVEMENTS\n","\n","1. Model Architecture Enhancements\n","\n","2. Training Optimizations\n","\n","3. Data Preprocessing Improvements\n","\n","4. Regularization \u0026 Generalization\n","\n","5. Evaluation \u0026 Post-Processing"]},{"cell_type":"markdown","metadata":{"id":"proGkW0mDr-w"},"source":["# TRANSFER LEARNING\n","\n","\n","\n","Transfer learning is a machine learning technique where a model trained on one task is reused for a different but related task. This allows us to:\n","\n"," - Leverage pre-learned features.\n","\n"," - Reduce training time since the model already has strong feature extraction capabilities.\n"," - Improve accuracy with limited data.\n","# Popular Transfer Learning Models\n","1. Image Classification Models\n","\n","- VGG16/VGG19\n","- ResNet (ResNet50, ResNet101, ResNet152)\n","- InceptionV3\n","- EfficientNet (EfficientNetB0 B7)\n","- MobileNetV2\n","I\n","\n","2. Natural Language Processing (NLP) Models\n","\n","- BERT (Bidirectional Encoder Representations from Transformers)\n","\n","- GPT (Generative Pre-trained Transformer, including GPT-3 \u0026 GPT-4)\n","- T5 (Text-To-Text Transfer Transformer)\n","- XLNet\n","\n","3. Object detection and segmentation models\n","- YOLO ( You Only Look Once, YOLOv4, YOLOv5, YOLOv8)\n","- Mask R-CNN\n","- Faster R-CNN\n","\n","4. Speech \u0026 Audio Processing Models\n","\n","- WaveNet\n","- DeepSpeech\n","- Whisper (by OpenAI)\n","\n","\n","check img 4:02"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hr9g3Oc0EnVg"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM4S6Mm3+DxkTY+VUxAWFwb","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}